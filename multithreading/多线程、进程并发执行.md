### python 对多并发编程的支持
* 多线程：threading，利用cpu和IO可以同时执行的原理，让cpu不会干巴巴等待IO完成
* multiprocessing，利用多核cpu的能力，真正的并行执行任务
* asyncio，在单线程利用cpu和IO同时执行的原理，实现函数异步执行

1. 使用Lock对资源加锁，防止冲突访问
2. 使用Queue实现不同线程/进程之间的数据通信，实现生产者-消费者模式
3. 使用线程池/进程池，简化线程/进程任务提交、等待结束、获取结果
4. 使用suprocess启动外部程序的进程，并进行输入输出交互

### python 怎样选择多线程多进程多协程
 并发编程三种方式：多线程，多进程，多协程Coroutine
 1. 什么是CPU密集型计算，Io密集型计算？
    ``` 
    计算密集型，CPU需要大量计算，占用cpu时间长，例如：压缩，解密加密，正则表达搜索
    CPU在等IO（硬盘/内存）的读写操作，cpu占用率低。例如：文件处理，读写数据库
    ```
2. 多线程多进程多协程对比
    ```
    多进程：
        优点：可以利用多核CPU并行运算
        缺点：占用资源多，可启动数目比线程少
        适用于：CPU密集型 
    多线程：
        优点：相比进程，更轻量级，占用资源少
        缺点：
            相比进程：多线程只能并发执行，不能利用多cpu（多核）
            相比协程：启动数目受限制，占用内存资源，有线程切换开销
        适用场景：IO密集型计算，同时运行的任务数要求不多
    多协程：
        优点：内存开销小，启动协程数量多
        缺点：支持的库有限制（aiohttp vs request）、代码实现复杂
        适用于： IO密集型计算，需要超多任务运行，但有现成库支持的场景
    ```
### python怎么根据任务选择对应的技术
任务特点： cpu 和 IO 密集型
1. cpu密集型：使用多进程multiprocess 
2. IO密集型： 选择多线程
    1. 需要超多任务量？使用多线程
    2. 有现成支持协程的库？协程
    3. 协程实现复杂度可接受？协程

### python 慢的原因？全局解释型锁GIL造成的？
1. python速度慢的原因
```
基础架构代码使用C/C++开发，python是动态类型语言，便解释边执行
无法利用多核CPU并发执行，GIL
```
2. GIL是什么呢
```
全局解释器锁（Global Interpreter Lock）GIL
解释器用于同步线程的一种机制，它使得任何时刻仅有一个线程在执行。即便是在多核处理器上，使用GIL解释器也只允许同一时间执行一个线程
```
3. 为什么有GIL这个东西呢？
```
为了解决多线程之间数据完整性和状态同步问题，由于开启多个线程使用一个cpu，轮流使用会破坏内存。
比如：thread1  intvalue =3 ，t1拿到cpu执行intvalue--，其值变为2.thread2拿到线程继续intvalue--操作，其值变为1.
再当thread1 拿到intvalue值就为1了，而不是2.破坏了内存

python解决了对共享资源的管理
```
4. 怎样规避GIL的限制？
```
1. 多线程机制依然是有用的，用于IO密集型计算
因为IO期间，线程会释放GIL，实现CPU和IO并行，因此多线程用于IO密集型计算依然可以大幅提升速度
但是多线程用于CPU计算，只会拖慢速度
2. 使用multiprocessing的多进程机制实行并行计算、利用多核cpu优势
为了应对GIL的问题，python提供了multiprocessing
```

### 如何使用多线程
1. python创建多线程的方法--code 01
```python
# 准备一个函数
def my_func(a,b):
    do_crwa(a,b)
# 2.创建一个多线程
import threading
t = threading.Thread(target=my_func,args=(100,200))
# 3. 启动线程
t.start()
# 4. 等待结束
t.join()
```

### python实现生产者消费爬虫
1. 多组建pipeline 技术架构
2. 生产者消费者爬虫架构
3. 多线程通信的queue.Queue 
``用于多线程之间的、线程安全的数据通信,多个线程返回数据是不冲突的``
```python 
# 1.导入类库
import queue
# 2.创建Queue
q = queue.Queue()
# 3. 添加元素
q.put(item)
#4.获取元素
item = q.get()
#5.查询状态
#查看元素的多少
q.qsize()
#判断是否为空
q.empty()
#判断是否已满
q.full()
```


### python线程安全问题以及解决
1. 线程安全概念介绍
```
线程安全指某个函数、函数库在多线程环境中被调用时，能够正确地处理多个线程之间的共享变量，使程序功能正确完成。线程切换造成线程不安全。
```
2. Lock用于解决线程安全问题
```python
# 用法1: try-finally模式
import threding
lock = threading.Lock()
lock.acquire()
try:
    #do something
finally:
    lock.release()

# 用法2: with模式
import threading 
lock = threading.Lock()
with lock:
    #do something 
```

### Python好用的线程池
1. 线程池的原理
```
新建----》就绪-----》运行-----》终止/阻塞-----》就绪
```
2. 使用线程池的好处
```python
# 1.提升性能：因为减去了大量新建、终止线程的开销，重用了线程资源
# 2.适用场景：适合处理突发性大量请求或需要大量线程完成任务、但实际任务处理时间较短
# 3.防御功能：能有效避免系统因为创建线程过多，而导致系统负荷过大相应变慢等问题
from concurrent.futures import ThreadPoolExecutor,as_completed
# 用法1: map函数，很简单。注意map的结果和入参时顺序对应的
with ThreadPoolExecutor() as pool:
    results := pool.map(craw,urls)
    for result in results:
        print(result)
# 用法2: future模式，更强大。注意如果用as_completed顺序是不定的
with ThreadPoolExecutor() as pool:
    results := [pool.map(craw,urls)
            for url in urls ]

    for future in as_completed(futures):
        print(future.result())
```

### python 实用线程池在web服务中的好处
1. web服务的架构以及特点
```
web浏览器 〉》 web服务器》〉》磁盘文件/数据库/远程服务API 
```
2. 使用线程池ThreadPoolExecutor加速
```
好处
1. 方便的将磁盘文件、数据库、远程API的IO调用并发执行
2. 线程池的线程数目不会无限创建（导致系统挂掉），具有防御功能
```
3. 代码用Flask实现web服务并实现加速

### python 多进程加速度程序运行
1. 有了多线程，为什么要用多进程
```
如果遇到了CPU密集型计算，多线程反而会降低执行速度
```
2. 多进程multiprocessing知识处理
```python 
# 多线程
# 引入模块
from threading import Thread
# 新建，启动，等待结束
t = Thread(target=func, args=(100,))
t.start()
t.join()
# 数据通信
import queue
q = queue.Queue()
q.put(item)
item = q.get()
# 线程安全加锁
from threading import Lock
lock = Lock()
with lock:
        # do something
# 池化技术
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor() as exectutor:
    # func1 
    result = exector.map(func, [1,2,3])

    # func2 
    result = future.result()

# 多进程
# 引入模块
from multiprocessing import Process
# 新建，启动，等待结束
p = Process(target=func, args=("bob",))
p.start()
p.join()
# 数据通信
from multiprocessing import Queue
q = Queue()
q.put([42, None, 'hello'])
item = q.get()
# 线程安全加锁
from multiprocess import Lock
lock = Lock()
with lock:
        # do something
# 池化技术
from concurrent.futures import ProcessPoolExecutor
with ThreadPoolExecutor() as exectutor:
    # func1 
    result = exector.map(func, [1,2,3])

    # func2 
    future = exector.submit(func1, 1)
    result = future.result()
```
3. 单线程、多线程、多进程对比CPU密集计算速度
```
多进程最快
```
### python异步IO实现并发爬虫
1. 单线程爬虫的执行路径
```
CPU--->等待--->CPU
```
2. 协程：在单线程内实现高并发
```
核心原理：用一个超级循环，配合IO多路复用原理（IO时CPU可以干其她事情）
```
3. python异步IO库介绍：asyncio
```python
import asyncio
# 获取事件循环
loop = asyncio.get_event_loop()

# 定义协程
async def myfunc(url):
    await get_url(url)

# 创建task列表
tasks = [loop.create_task(myfunc(url)) for url in urls]

# 执行爬虫事件列表
loop.run_until_complete(asyncio.waiat(tasks))

注意：
要用在异步IO变成中
依赖的库必须支持一步IO特性

爬虫引用中：
requests 不支持异步
需要用aiohttp

```

### python 在异步IO中使用信号量，控制爬虫并发度
1.信号量：是一个同步对象
* 当线程完成一次对semaphore对象的等待wait时，该计数值减一，
* 当线程完成一次对semaphore对象的释放release时，该计数值加一，
* 当计数值为0，则线程等待该semphore对象不再能成功直至该semaphore对象变为signaled状态
* samephore对象的计数值大于0，为signaled状态，计数值等于0，为nonsignaled状态
```python
# 使用方式1
sem = asyncio.Semaphore(10)
# ....later
async with sem:
    # work wiath shared resource 

# 使用方式2 
sem = asyncio.Semaphore(10)
# ...later
await sem.acquire()
try:
        # work with shared resource
finally:
    sem.release()
```